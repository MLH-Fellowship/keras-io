{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug\n",
    "\n",
    "Force no GPU. Used for local development. Remove when submitting notebook to Keras in PR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pSVUTJKt7Lua"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This example shows how to train a neural network to recognize text in images.  We use Keras's functional API to implement a model based on the CRNN architecture. We also create both a custom loss function to adapt the CTC loss provided by `tensorflow.keras.backend`, as well as a custom metric to adapt `tf.edit_distance`. \n",
    "\n",
    "To demonstrate this setup, we build a training dataset by generating synthetic images from a source list of words. To implement the dataset, we subclass `tensorflow.keras.utils.Sequence`. It provides an `on_epoch_end` callback, which we use for curriculum learning by gradually ramping up the difficulty of the dataset during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TkHFVs1s7Lus"
   },
   "source": [
    "## Setup\n",
    "\n",
    "One external package is required for this example.\n",
    "* `cairocffi` provides Python bindings for `cairo`, a 2D vector graphics library written in the C programming language. We use this package to generate synthetic images of text.\n",
    "\n",
    "If you've opened this example in Google Colab, you can install the package like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7O-Kb0Rx7Lux"
   },
   "outputs": [],
   "source": [
    "!pip install cairocffi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GhawkgM3uABU"
   },
   "source": [
    "Then, import the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "INZxFXyFuEVH"
   },
   "outputs": [],
   "source": [
    "# TensorFlow packages\n",
    "from tensorflow.keras import layers, losses, models, optimizers, utils\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# Third-party packages\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import cairocffi as cairo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eki6hmPR7Lu-"
   },
   "source": [
    "## Preparing a synthetic dataset\n",
    "\n",
    "We train our neural network on a dataset that contains synthetic images. The synthetic images are generated on the fly from a list of source words. \n",
    "\n",
    "> _**Note:** Other text-image datasets exist, some of which are widely used in OCR research. However, these datasets can be quite large, making them difficult to handle in a code example. If you plan to adapt this tutorial for your own work, consider using one of the following datasets instead: [MJSynth (MJ)](http://www.robots.ox.ac.uk/~vgg/data/text/), [SynthText (ST)](http://www.robots.ox.ac.uk/~vgg/data/scenetext/), [IIIT](http://cvit.iiit.ac.in/projects/SceneTextUnderstanding/IIIT5K.html), [SVT](http://www.iapr-tc11.org/mediawiki/index.php/The_Street_View_Text_Dataset), [IC03](http://www.iapr-tc11.org/mediawiki/index.php/ICDAR_2003_Robust_Reading_Competitions), [IC13](http://rrc.cvc.uab.es/?ch=2), [IC15](http://rrc.cvc.uab.es/?ch=4), [SVTP](http://openaccess.thecvf.com/content_iccv_2013/papers/Phan_Recognizing_Text_with_2013_ICCV_paper.pdf), and/or [CUTE](http://cs-chan.com/downloads_CUTE80_dataset.html)._\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a2128O6wABUf"
   },
   "source": [
    "### Downloading the source word lists\n",
    "\n",
    "First, let's download and uncompress an archive containing two text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R_2lv4ZC7Lvf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "tgz_path = Path(\n",
    "    utils.get_file('wordlists.tgz',\n",
    "                   origin='http://www.mythic-ai.com/datasets/wordlists.tgz',\n",
    "                   untar=True)\n",
    ")\n",
    "dataset_dir = tgz_path.parent\n",
    "\n",
    "wordlists = [f.name for f in dataset_dir.iterdir() if f.suffix == '.txt']\n",
    "print(f\".txt files contained in wordlists.tgz: {wordlists}\")\n",
    "\n",
    "monogram_file = dataset_dir / \"wordlist_mono_clean.txt\"\n",
    "bigram_file   = dataset_dir / \"wordlist_bi_clean.txt\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zDdkU3GoyRO0"
   },
   "source": [
    "Each file contains a different set of [**n-gram**](https://en.wikipedia.org/wiki/N-gram) data samples:\n",
    "* `wordlist_mono_clean.txt` contains a list of **monograms**, or single words. These words have been pre-sorted according to their frequency in English speech.\n",
    "* `wordlist_bi_clean.txt` contains a list of **bigrams**, or pairs of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZADLVFG0SV6"
   },
   "outputs": [],
   "source": [
    "monogram_sample, bigram_sample = [], []\n",
    "i = 5\n",
    "with monogram_file.open() as f_m, bigram_file.open() as f_b: \n",
    "    for _ in range(i):\n",
    "        monogram_sample.append(f_m.readline().rstrip())\n",
    "        bigram_sample.append(f_b.readline().rstrip())\n",
    "\n",
    "print(f\"First {i} monograms: {monogram_sample}\")\n",
    "print(f\"First {i} bigrams: {bigram_sample}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2KzE6ZG_3A43"
   },
   "source": [
    "### Loading and preprocessing words\n",
    "\n",
    "Before using these word lists to create a dataset, we filter out any unsuitable examples as we load them into memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ephLzSDv9HAR"
   },
   "outputs": [],
   "source": [
    "# Criteria 1: Text sequences must be under a specified length\n",
    "ABSOLUTE_MAX_STRING_LEN = 16\n",
    "\n",
    "# Criteria 2: Text sequences must contain only specified characters\n",
    "ALPHABET = u'abcdefghijklmnopqrstuvwxyz '\n",
    "\n",
    "import re\n",
    "\n",
    "def preprocess_words(wordlist_file, valid_characters, max_string_len=None):\n",
    "    def _is_valid_str(in_str):\n",
    "        search = re.compile(rf'^[{valid_characters} ]+$', re.UNICODE).search\n",
    "        return bool(search(in_str))\n",
    "\n",
    "    def _is_length_of_word_valid(word):\n",
    "        return (max_string_len == -1 or\n",
    "                max_string_len is None or\n",
    "                len(word) <= max_string_len)\n",
    "\n",
    "    valid_words = []\n",
    "    with wordlist_file.open() as f:\n",
    "        for line in f:\n",
    "            word = line.rstrip()\n",
    "            if _is_valid_str(word) and _is_length_of_word_valid(word):\n",
    "                valid_words.append(word)\n",
    "\n",
    "    return valid_words\n",
    "\n",
    "monograms = preprocess_words(monogram_file, ALPHABET, ABSOLUTE_MAX_STRING_LEN)\n",
    "bigrams   = preprocess_words(bigram_file, ALPHABET, ABSOLUTE_MAX_STRING_LEN)\n",
    "\n",
    "print(f\"Wordlists contain {len(monograms)} valid monograms\" \n",
    "      f\" and {len(bigrams)} valid bigrams.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SJ44fwg5tWY6"
   },
   "source": [
    "### Set aside words for validation\n",
    "\n",
    "Because the monograms have been ordered by frequency, simply slicing the dataset using Python's list indexing will cause easy and difficult words to be distributed unevenly. We'll instead define a function that uses a slightly more involved approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wCx7lrf4tWtk"
   },
   "outputs": [],
   "source": [
    "VALID_SPLIT = 0.2\n",
    "\n",
    "def valid_split(input_list, split_ratio):\n",
    "    n = round(1 / split_ratio)\n",
    "    trn_list, val_list = [], []\n",
    "    for i, item in enumerate(input_list):\n",
    "        if i % n == 0:\n",
    "            val_list.append(item)\n",
    "        else:\n",
    "            trn_list.append(item)\n",
    "\n",
    "    return trn_list, val_list\n",
    "\n",
    "trn_monograms, val_monograms = valid_split(monograms, VALID_SPLIT)\n",
    "trn_bigrams, val_bigrams = valid_split(bigrams, VALID_SPLIT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y9go0Eje7LwE"
   },
   "source": [
    "### Defining functions for creating synthetic text images\n",
    "\n",
    "These functions generate images from strings of text. They include image transformations to introduce variations in the generated images, too. This helps to improve the capacity of the model, and lower the risk of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g_tN4Zzk7Lwe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# this creates larger \"blotches\" of noise which look\n",
    "# more realistic than just adding gaussian noise\n",
    "# assumes greyscale with pixels ranging from 0 to 1\n",
    "\n",
    "def speckle(img):\n",
    "    severity = np.random.uniform(0, 0.6)\n",
    "    blur = ndimage.gaussian_filter(np.random.randn(*img.shape) * severity, 1)\n",
    "    img_speck = (img + blur)\n",
    "    img_speck[img_speck > 1] = 1\n",
    "    img_speck[img_speck <= 0] = 0\n",
    "    return img_speck\n",
    "\n",
    "\n",
    "# paints the string in a random location the bounding box\n",
    "# also uses a random font, a slight random rotation,\n",
    "# and a random amount of speckle noise\n",
    "\n",
    "def paint_text(text, w, h, rotate=False, ud=False, multi_fonts=False):\n",
    "    surface = cairo.ImageSurface(cairo.FORMAT_RGB24, w, h)\n",
    "    with cairo.Context(surface) as context:\n",
    "        context.set_source_rgb(1, 1, 1)  # White\n",
    "        context.paint()\n",
    "        # this font list works in CentOS 7\n",
    "        if multi_fonts:\n",
    "            fonts = [\n",
    "                'Century Schoolbook', 'Courier', 'STIX',\n",
    "                'URW Chancery L', 'FreeMono']\n",
    "            context.select_font_face(\n",
    "                np.random.choice(fonts),\n",
    "                cairo.FONT_SLANT_NORMAL,\n",
    "                np.random.choice([cairo.FONT_WEIGHT_BOLD, cairo.FONT_WEIGHT_NORMAL]))\n",
    "        else:\n",
    "            context.select_font_face('Courier',\n",
    "                                     cairo.FONT_SLANT_NORMAL,\n",
    "                                     cairo.FONT_WEIGHT_BOLD)\n",
    "        context.set_font_size(25)\n",
    "        box = context.text_extents(text)\n",
    "        border_w_h = (4, 4)\n",
    "        if box[2] > (w - 2 * border_w_h[1]) or box[3] > (h - 2 * border_w_h[0]):\n",
    "            print(text)\n",
    "            print(box[0])\n",
    "            print(box[1])\n",
    "            raise IOError(('Could not fit string into image.'\n",
    "                           'Max char count is too large for given image width.'))\n",
    "\n",
    "        # teach the RNN translational invariance by\n",
    "        # fitting text box randomly on canvas, with some room to rotate\n",
    "        max_shift_x = w - box[2] - border_w_h[0]\n",
    "        max_shift_y = h - box[3] - border_w_h[1]\n",
    "        top_left_x = np.random.randint(0, int(max_shift_x))\n",
    "        if ud:\n",
    "            top_left_y = np.random.randint(0, int(max_shift_y))\n",
    "        else:\n",
    "            top_left_y = h // 2\n",
    "        context.move_to(top_left_x - int(box[0]), top_left_y - int(box[1]))\n",
    "        context.set_source_rgb(0, 0, 0)\n",
    "        context.show_text(text)\n",
    "\n",
    "    buf = surface.get_data()\n",
    "    a = np.frombuffer(buf, np.uint8)\n",
    "    a.shape = (h, w, 4)\n",
    "    a = a[:, :, 0]  # grab single channel\n",
    "    a = a.astype(np.float32) / 255\n",
    "    a = np.expand_dims(a, 0)\n",
    "    if rotate:\n",
    "        a = image.random_rotation(a, 3 * (w - top_left_x) / w + 1)\n",
    "    a = speckle(a)\n",
    "\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Xz8cxGC7Lwn"
   },
   "source": [
    "### Building the dataset using the `Sequence` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0RARl2u27LwT",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_H = 64\n",
    "IMG_W = 128\n",
    "DOWNSAMPLE_FACTOR = 4\n",
    "\n",
    "SUBSET_NUM = 12800     # Number of words to pull from source lists into a subset\n",
    "MAX_WORD_LEN = 4       # Starting max word length within subset\n",
    "BLANK_RATIO = 0.2      # Ratio of blanks to words\n",
    "MONO_BI_RATIO = 1      # Ratio of monograms to bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dW1-JxuU7Lwp",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "class TextImageSequence(utils.Sequence):\n",
    "    def __init__(self, monograms, bigrams, batch_size, \n",
    "                 img_w, img_h, downsample_factor,\n",
    "                 subset_num=-1, max_word_len=4, mono_bi_ratio=1, \n",
    "                 blank_ratio=0, start_epoch=0):\n",
    "        self.batch_size = batch_size\n",
    "        self.epoch_num = start_epoch\n",
    "        self.downsample_factor = downsample_factor\n",
    "\n",
    "        # Config settings for synthetic image generation function\n",
    "        self.img_w = img_w \n",
    "        self.img_h = img_h \n",
    "        self.rotate=False\n",
    "        self.ud=False\n",
    "        self.multi_fonts=False\n",
    "        \n",
    "        # Base wordlists\n",
    "        self.monograms = monograms\n",
    "        self.bigrams = bigrams\n",
    "\n",
    "        # Config settings for creating a wordlist subset\n",
    "        self.subset_num = subset_num\n",
    "        self.max_word_len = max_word_len\n",
    "        self.mono_bi_ratio = mono_bi_ratio\n",
    "        self.blank_ratio = blank_ratio\n",
    "\n",
    "        self._build_word_subset()\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.X) // self.batch_size)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # Width and height are backwards from typical Keras convention,\n",
    "        # because width is the time dimension when it gets fed into the RNN\n",
    "        X_batch = np.ones([self.batch_size, self.img_w, self.img_h, 1])\n",
    "        y_batch = np.ones([self.batch_size, ABSOLUTE_MAX_STRING_LEN + 2])\n",
    "        \n",
    "        # TODO: For loop -> list comprehension / fancy slicing / map\n",
    "        for i in range(self.batch_size):\n",
    "            X_batch[i, 0:self.img_w, :, 0] = (\n",
    "                paint_text(self.X[index + i],\n",
    "                           self.img_w, self.img_h,\n",
    "                           self.rotate,\n",
    "                           self.ud,\n",
    "                           self.multi_fonts)[0, :, :].T\n",
    "            )\n",
    "            y_batch[i] = self.y[index + i]\n",
    "        \n",
    "        return X_batch, y_batch\n",
    "\n",
    "    def _text_to_labels(self, text):\n",
    "        # to use k.backend.ctc_batch_loss, 3 pieces of information are needed:\n",
    "        #   1. y_true (text, in integer form, padded out to max string length)\n",
    "        #   2. sequence length for each batch item in y_true\n",
    "        #   3. sequence length for each batch item in y_pred\n",
    "        if text == ' ':\n",
    "            y_true = ([len(ALPHABET)] +                            # blank val\n",
    "                      [-1]*(ABSOLUTE_MAX_STRING_LEN - len(text)))  # padding\n",
    "        else:\n",
    "            y_true = ([ALPHABET.find(c) for c in text] +           # char -> int\n",
    "                      [-1]*(ABSOLUTE_MAX_STRING_LEN - len(text)))  # padding\n",
    "        y_true_len = [len(text)]\n",
    "        y_pred_len = [self.img_w // self.downsample_factor - 2]\n",
    "\n",
    "        # Keras losses only accept 2 inputs (label, y_pred), so we\n",
    "        # concatenate the 3 pieces of information into a single label\n",
    "        label = y_pred_len + y_true_len + y_true\n",
    "\n",
    "        return label\n",
    "\n",
    "    def _build_word_subset(self):\n",
    "        string_list=  []\n",
    "\n",
    "        # Enforce ratio of blanks:words, and ratio of monograms:bigrams\n",
    "        num_blanks = round(self.subset_num * self.blank_ratio)\n",
    "        num_words = self.subset_num - num_blanks\n",
    "        num_monograms = round(num_words * self.mono_bi_ratio)\n",
    "\n",
    "        for monogram in self.monograms:\n",
    "            if len(string_list) == num_monograms and self.subset_num is not -1:\n",
    "                break\n",
    "            if len(monogram) <= self.max_word_len:\n",
    "                string_list.append(monogram)\n",
    "\n",
    "        for bigram in self.bigrams:\n",
    "            if len(string_list) == num_words and self.subset_num is not -1:\n",
    "                break\n",
    "            if len(bigram) <= self.max_word_len:\n",
    "                string_list.append(bigram)\n",
    "\n",
    "        for _ in range(num_blanks):\n",
    "            string_list.append(' ')\n",
    "        \n",
    "        if len(string_list) < self.subset_num:\n",
    "            # Possibly raise only Warning? Not a fatal issue...\n",
    "            raise IOError(f'Could only pull {len(string_list)} words into '\n",
    "                            f'subset when {self.subset_num} were requested.')\n",
    "            \n",
    "        random.shuffle(string_list)\n",
    "\n",
    "        self.X = string_list\n",
    "        self.y = [self._text_to_labels(t) for t in string_list]\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        # Update paint function parameters to implement curriculum learning\n",
    "        self.epoch_num += 1\n",
    "        if self.epoch_num >= 3:\n",
    "            self.ud=True\n",
    "        if self.epoch_num >= 6:\n",
    "            self.multi_fonts=True\n",
    "        if self.epoch_num >= 9:\n",
    "            self.rotate=True\n",
    "\n",
    "        # Hypothetical implementation for other curriculum learning setups\n",
    "        # if self.epoch_num % 2 == 0:\n",
    "        #     # Ramp up the length of allowable words to max\n",
    "        #     if self.max_word_len < ABSOLUTE_MAX_STRING_LEN:\n",
    "        #         self.max_word_len += 1\n",
    "\n",
    "        #     # Ramp up towards a 50/50 split of monograms and bigrams\n",
    "        #     self.mono_bi_ratio -= (self.mono_bi_ratio - 0.5) * 0.1\n",
    "\n",
    "        #     # Rebuild the wordlist\n",
    "        #     self._build_word_subset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rJi_3KE97Lwu"
   },
   "source": [
    "Create Sequence dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q4NzcdZw7Lwv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trn_dataset = TextImageSequence(trn_monograms, trn_bigrams, BATCH_SIZE, \n",
    "                                IMG_W, IMG_H, DOWNSAMPLE_FACTOR, SUBSET_NUM,\n",
    "                                MAX_WORD_LEN, MONO_BI_RATIO, BLANK_RATIO)\n",
    "val_dataset = TextImageSequence(val_monograms, val_bigrams, BATCH_SIZE, \n",
    "                                IMG_W, IMG_H, DOWNSAMPLE_FACTOR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u6vNv3bc7Lw0"
   },
   "source": [
    "Visualize images from a sample batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZsezGVCk7Lw0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sample_batch = next(iter(trn_dataset))\n",
    "\n",
    "f, axarr = plt.subplots(5, 2)\n",
    "for i, ax in enumerate(f.axes):\n",
    "    # Image is in (W, H, 1) format. Squeeze changes this to (W, H), and .T\n",
    "    # transposes it to (H, W), allowing it to be displayed as grayscale image\n",
    "    ax.imshow(np.squeeze(sample_batch[0][i]).T, cmap='gray', vmin=0, vmax=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KOy1YaNO7Lw8"
   },
   "source": [
    "## Preparing the model, optimizer, loss function, and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BSu5AxnQ7LxB"
   },
   "source": [
    "### Model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1HbPh_0a7LxC"
   },
   "outputs": [],
   "source": [
    "conv_filters = 16\n",
    "kernel_size = (3, 3)\n",
    "pool_size = 2\n",
    "time_dense_size = 32\n",
    "rnn_size = 512\n",
    "act = 'relu'\n",
    "\n",
    "# Input layers ()\n",
    "X = layers.Input(shape=(IMG_W, IMG_H, 1), dtype='float32')\n",
    "\n",
    "# Convolution layers\n",
    "inner = layers.Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                activation=act, kernel_initializer='he_normal',\n",
    "                name='conv1')(X)\n",
    "inner = layers.MaxPooling2D(pool_size=(pool_size, pool_size), name='max1')(inner)\n",
    "inner = layers.Conv2D(conv_filters, kernel_size, padding='same',\n",
    "                activation=act, kernel_initializer='he_normal',\n",
    "                name='conv2')(inner)\n",
    "inner = layers.MaxPooling2D(pool_size=(pool_size, pool_size), name='max2')(inner)\n",
    "\n",
    "conv_to_rnn_dims = (IMG_W // (pool_size ** 2),\n",
    "                    (IMG_H // (pool_size ** 2)) * conv_filters)\n",
    "inner = layers.Reshape(target_shape=conv_to_rnn_dims, name='reshape')(inner)\n",
    "\n",
    "# cuts down input size going into RNN:\n",
    "inner = layers.Dense(time_dense_size, activation=act, name='dense1')(inner)\n",
    "\n",
    "# Recurrent layers: Two layers of bidirectional GRUs\n",
    "# GRU seems to work as well, if not better than LSTM:\n",
    "gru_1 = layers.GRU(rnn_size, return_sequences=True,\n",
    "            kernel_initializer='he_normal', name='gru1')(inner)\n",
    "gru_1b = layers.GRU(rnn_size, return_sequences=True,\n",
    "                go_backwards=True, kernel_initializer='he_normal',\n",
    "                name='gru1_b')(inner)\n",
    "gru1_merged = layers.add([gru_1, gru_1b])\n",
    "gru_2 = layers.GRU(rnn_size, return_sequences=True,\n",
    "            kernel_initializer='he_normal', name='gru2')(gru1_merged)\n",
    "gru_2b = layers.GRU(rnn_size, return_sequences=True, go_backwards=True,\n",
    "                kernel_initializer='he_normal', name='gru2_b')(gru1_merged)\n",
    "\n",
    "# transforms RNN output to character activations:\n",
    "inner = layers.Dense(len(ALPHABET)+1, kernel_initializer='he_normal',\n",
    "                name='dense2')(layers.concatenate([gru_2, gru_2b]))\n",
    "y_pred = layers.Activation('softmax', name='softmax')(inner)\n",
    "\n",
    "model = models.Model(inputs=X, outputs=y_pred)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wqj06B2AZxgs"
   },
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C-IHhn2LYZOC"
   },
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(learning_rate=0.001,\n",
    "                     decay=1e-6,\n",
    "                     momentum=0.9,\n",
    "                     nesterov=True,\n",
    "                     clipnorm=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iBqf6dWQaGxS"
   },
   "source": [
    "### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gmreYKCZaKIR"
   },
   "outputs": [],
   "source": [
    "def ctc_loss(y, y_pred):\n",
    "    # Decompose label into its subsequent parts\n",
    "    input_length = y[:, 0:1]\n",
    "    label_length = y[:, 1:2]\n",
    "    y_true = y[:, 2:] \n",
    "\n",
    "    # From old example: \"the first couple outputs of the RNN tend to be garbage\"\n",
    "    y_pred = y_pred[:, 2:, :]\n",
    "    \n",
    "    return K.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VjJeLQ78aLSF"
   },
   "source": [
    "### Evaluation metrics\n",
    "\n",
    "Adapt old functionality to custom Keras metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JJcE3VVyaUcP"
   },
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "def edit_distance(y, y_pred):\n",
    "    # Decompose label into its subsequent parts\n",
    "    input_length = y[:, 0:1]\n",
    "    label_length = y[:, 1:2]\n",
    "    y_true = y[:, 2:]\n",
    "\n",
    "    # This form is required by ctc_label_dense_to_sparse and ctc_greedy_decoder\n",
    "    input_length = tf.cast(tf.squeeze(input_length, axis=-1), tf.int32)\n",
    "    label_length = tf.cast(tf.squeeze(label_length, axis=-1), tf.int32)\n",
    "\n",
    "    # Get int64 SparseTensor representation of y_true\n",
    "    y_true_sparse = K.ctc_label_dense_to_sparse(y_true, label_length)\n",
    "    y_true_sparse = tf.cast(y_true_sparse, tf.int64)\n",
    "\n",
    "    # Get int64 SparseTensor representation of y_pred\n",
    "    y_pred = tf.transpose(y_pred, [1, 0, 2]) \n",
    "    decoded, neg_sum_logits = tf.nn.ctc_greedy_decoder(y_pred, input_length)\n",
    "    y_pred_sparse = decoded[0]\n",
    "\n",
    "    # Calculate Levenshtein distance for batch\n",
    "    dist_batch = tf.edit_distance(y_pred_sparse, y_true_sparse)\n",
    "\n",
    "    return tf.reduce_mean(dist_batch, axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ygni391ra1J"
   },
   "source": [
    "## Bringing it all together: the training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RqbV6JuiwnS5"
   },
   "outputs": [],
   "source": [
    "model.compile(loss=ctc_loss, optimizer=sgd, metrics=[edit_distance])\n",
    "model.fit(trn_dataset, batch_size=BATCH_SIZE, epochs=20, shuffle=True,\n",
    "          validation_data=val_dataset)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "image_ocr_new.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
