{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset - Wordlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import utils\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ABSOLUTE_MAX_STRING_LEN = 16\n",
    "MINIBATCH_SIZE = 32\n",
    "VAL_SPLIT = 0.2\n",
    "ALPHABET = u'abcdefghijklmnopqrstuvwxyz '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and uncompress archive of raw word source lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fdir = os.path.dirname(\n",
    "    utils.get_file('wordlists.tgz',\n",
    "                   origin='http://www.mythic-ai.com/datasets/wordlists.tgz',\n",
    "                   untar=True)\n",
    ")\n",
    "monogram_file = os.path.join(fdir, 'wordlist_mono_clean.txt')\n",
    "bigram_file = os.path.join(fdir, 'wordlist_bi_clean.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`build_word_list`: Function that builds a list of words satisfying the following criteria:\n",
    "* Only words with lowercase alphabetic characters and spaces are included\n",
    "* Words greater than `max_string_len` are excluded\n",
    "* The ratio of monograms to bigrams is made to equal to `mono_fraction`\n",
    "* Common words are interlaced with uncommon words (based on their frequency in English speech)\n",
    "* Mixing in blank words. Prevously handled by data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def build_word_list(num_words, max_string_len=None, mono_fraction=0.5):\n",
    "    assert max_string_len <= ABSOLUTE_MAX_STRING_LEN\n",
    "    assert num_words % MINIBATCH_SIZE == 0\n",
    "    assert (VAL_SPLIT * num_words) % MINIBATCH_SIZE == 0\n",
    "\n",
    "    string_list = [''] * num_words\n",
    "    tmp_string_list = []\n",
    "    X_text = []\n",
    "    Y_data = np.ones([num_words, ABSOLUTE_MAX_STRING_LEN]) * -1\n",
    "    Y_len = [0] * num_words\n",
    "    \n",
    "    def _text_to_labels(text):\n",
    "        ret = []\n",
    "        for char in text:\n",
    "            ret.append(ALPHABET.find(char))\n",
    "        return ret\n",
    "    \n",
    "    def _is_valid_str(in_str):\n",
    "        search = re.compile(r'^[a-z ]+$', re.UNICODE).search\n",
    "        return bool(search(in_str))\n",
    "\n",
    "    def _is_length_of_word_valid(word):\n",
    "        return (max_string_len == -1 or\n",
    "                max_string_len is None or\n",
    "                len(word) <= max_string_len)\n",
    "\n",
    "    # monogram file contains words sorted by frequency in english speech\n",
    "    with open(monogram_file, mode='r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if len(tmp_string_list) == int(num_words * mono_fraction):\n",
    "                break\n",
    "            word = line.rstrip()\n",
    "            if _is_length_of_word_valid(word):\n",
    "                tmp_string_list.append(word)\n",
    "\n",
    "    # bigram file contains common word pairings in english speech\n",
    "    with open(bigram_file, mode='r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if len(tmp_string_list) == num_words:\n",
    "                break\n",
    "            columns = line.lower().split()\n",
    "            word = columns[0] + ' ' + columns[1]\n",
    "            if _is_valid_str(word) and _is_length_of_word_valid(word):\n",
    "                tmp_string_list.append(word)\n",
    "                \n",
    "    if len(tmp_string_list) != num_words:\n",
    "        raise IOError('Could not pull enough words'\n",
    "                      'from supplied monogram and bigram files.')\n",
    "        \n",
    "    # interlace to mix up the easy and hard words\n",
    "    string_list[::2] = tmp_string_list[:num_words // 2]\n",
    "    string_list[1::2] = tmp_string_list[num_words // 2:]\n",
    "    \n",
    "    # insert blank words every 4th word\n",
    "    for i in range(0, num_words, 4):\n",
    "        string_list.insert(i, '')\n",
    "    string_list = string_list[:num_words]\n",
    "\n",
    "    for i, word in enumerate(string_list):\n",
    "        Y_len[i] = len(word)\n",
    "        Y_data[i, 0:len(word)] = _text_to_labels(word)\n",
    "        X_text.append(word)\n",
    "    Y_len = np.expand_dims(np.array(Y_len), 1)\n",
    "   \n",
    "    return X_text, Y_data, Y_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build initial wordlist of 16000 short monograms (len < 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_t, Y_d, Y_l = build_word_list(num_words=16000, max_string_len=4, mono_fraction=1)\n",
    "\n",
    "print(len(X_t))\n",
    "print(\"First five words:\")\n",
    "print(X_t[:5])\n",
    "print(\"\\n\" + \"First five words converted to integer labels:\")\n",
    "print(Y_d[:5])\n",
    "print(\"\\n\" + \"Length of each word:\")\n",
    "print(Y_l[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}